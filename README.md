# Customer Service RAG System
# å®¢æœRAGç³»ç»Ÿ

A production-ready customer service system using Corrective RAG to reduce hallucinations and improve answer quality.

ä¸€ä¸ªä½¿ç”¨çŸ«æ­£å¼RAGçš„ç”Ÿäº§å°±ç»ªå®¢æœç³»ç»Ÿï¼Œç”¨äºå‡å°‘å¹»è§‰å¹¶æé«˜ç­”æ¡ˆè´¨é‡ã€‚

![System Architecture](https://via.placeholder.com/800x200/2196F3/FFFFFF?text=Customer+Service+RAG+System)

## ğŸŒŸ Features / åŠŸèƒ½ç‰¹æ€§

âœ… **Corrective RAG Pipeline** - Automatic relevance grading and query rewriting  
   çŸ«æ­£å¼RAGæµç¨‹ - è‡ªåŠ¨ç›¸å…³æ€§è¯„åˆ†å’ŒæŸ¥è¯¢é‡å†™

âœ… **Source Citation** - Every answer includes confidence scores and sources  
   æ¥æºå¼•ç”¨ - æ¯ä¸ªç­”æ¡ˆåŒ…å«ç½®ä¿¡åº¦åˆ†æ•°å’Œæ¥æº

âœ… **Bilingual Support** - English and Chinese interface and processing  
   åŒè¯­æ”¯æŒ - è‹±ä¸­æ–‡ç•Œé¢å’Œå¤„ç†

âœ… **Knowledge Base Management** - Upload, delete, and organize documents  
   çŸ¥è¯†åº“ç®¡ç† - ä¸Šä¼ ã€åˆ é™¤å’Œç»„ç»‡æ–‡æ¡£

âœ… **Persistent Storage** - Qdrant vector database for reliable storage  
   æŒä¹…åŒ–å­˜å‚¨ - Qdrantå‘é‡æ•°æ®åº“æä¾›å¯é å­˜å‚¨

âœ… **Conversation History** - Context-aware multi-turn conversations  
   å¯¹è¯å†å² - ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„å¤šè½®å¯¹è¯

## ğŸ“‹ System Architecture / ç³»ç»Ÿæ¶æ„

```
User Input â†’ Streamlit Interface â†’ Chat Service
                â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                â†“         â†“          â†“
    Retriever      Reranker  Query Rewriter  Generator
        â†“                â†“         â†“          â†“
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
                  OpenAI API + Qdrant
                        â†“
                 Final Response
```

## ğŸš€ Quick Start / å¿«é€Ÿå¼€å§‹

### Prerequisites / å‰ææ¡ä»¶

- Python 3.8+
- Docker and Docker Compose
- OpenAI API key

### Installation / å®‰è£…

1. **Clone the repository / å…‹éš†ä»“åº“**
```bash
git clone <your-repo-url>
cd customer-service-rag
```

2. **Create virtual environment / åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies / å®‰è£…ä¾èµ–**
```bash
pip install -r requirements.txt
```

4. **Set up environment variables / è®¾ç½®ç¯å¢ƒå˜é‡**
```bash
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY
# ç¼–è¾‘.envå¹¶æ·»åŠ ä½ çš„OPENAI_API_KEY
```

5. **Start Qdrant / å¯åŠ¨Qdrant**
```bash
docker-compose up -d
```

6. **Initialize vector database / åˆå§‹åŒ–å‘é‡æ•°æ®åº“**
```bash
python scripts/init_vector_db.py
```

7. **Load knowledge base / åŠ è½½çŸ¥è¯†åº“**
```bash
python scripts/load_knowledge_base.py
```

8. **Run the application / è¿è¡Œåº”ç”¨**
```bash
streamlit run app.py
```

The application will open at `http://localhost:8501`

## ğŸ“ Project Structure / é¡¹ç›®ç»“æ„

```
customer-service-rag/
â”œâ”€â”€ app.py                    # Streamlit application / ä¸»åº”ç”¨
â”œâ”€â”€ chat_service.py          # RAG pipeline orchestration / RAGæµç¨‹ç¼–æ’
â”œâ”€â”€ knowledge_service.py     # Knowledge base management / çŸ¥è¯†åº“ç®¡ç†
â”œâ”€â”€ retriever.py             # Document retrieval / æ–‡æ¡£æ£€ç´¢
â”œâ”€â”€ reranker.py              # Relevance scoring / ç›¸å…³æ€§è¯„åˆ†
â”œâ”€â”€ query_rewriter.py        # Query rewriting / æŸ¥è¯¢é‡å†™
â”œâ”€â”€ generator.py             # Answer generation / ç­”æ¡ˆç”Ÿæˆ
â”œâ”€â”€ vector_store.py          # Qdrant interface / Qdrantæ¥å£
â”œâ”€â”€ llm_client.py            # OpenAI wrapper / OpenAIå°è£…
â”œâ”€â”€ config.py                # Configuration / é…ç½®
â”œâ”€â”€ document_loader.py       # Document processing / æ–‡æ¡£å¤„ç†
â”œâ”€â”€ logger_config.py         # Logging setup / æ—¥å¿—é…ç½®
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ knowledge_base/      # Sample documents / ç¤ºä¾‹æ–‡æ¡£
â”‚   â””â”€â”€ uploads/             # User uploads / ç”¨æˆ·ä¸Šä¼ 
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ init_vector_db.py    # Initialize Qdrant / åˆå§‹åŒ–Qdrant
â”‚   â””â”€â”€ load_knowledge_base.py  # Load documents / åŠ è½½æ–‡æ¡£
â””â”€â”€ requirements.txt         # Dependencies / ä¾èµ–é¡¹
```

## ğŸ”§ Configuration / é…ç½®

Edit `.env` file to customize:

```bash
# OpenAI
OPENAI_API_KEY=sk-...
LLM_MODEL=gpt-4-turbo-preview
EMBEDDING_MODEL=text-embedding-3-small

# Qdrant
QDRANT_HOST=localhost
QDRANT_PORT=6333

# RAG Parameters
TOP_K=5
RELEVANCE_THRESHOLD=0.7
CHUNK_SIZE=500
CHUNK_OVERLAP=50
```

## ğŸ“š Usage Examples / ä½¿ç”¨ç¤ºä¾‹

### Chat Interface / å¯¹è¯ç•Œé¢

1. Open the application at `http://localhost:8501`
2. Type your question in English or Chinese
3. View the answer with sources and confidence score
4. Continue the conversation with context awareness

### Knowledge Base Management / çŸ¥è¯†åº“ç®¡ç†

1. Navigate to "Knowledge Base" tab
2. View existing documents and statistics
3. Upload new documents (.txt, .pdf, .docx)
4. Delete documents you no longer need

### Programmatic Usage / ç¼–ç¨‹ä½¿ç”¨

```python
from vector_store import create_vector_store
from llm_client import create_llm_client
from chat_service import create_chat_service

# Initialize services
vector_store = create_vector_store()
llm_client = create_llm_client()
chat_service = create_chat_service(vector_store, llm_client)

# Process query
response = chat_service.process_query("What is the refund policy?")

print(f"Answer: {response['answer']}")
print(f"Confidence: {response['confidence']}")
print(f"Sources: {response['sources']}")
```

## ğŸ”„ Corrective RAG Workflow / çŸ«æ­£å¼RAGå·¥ä½œæµ

```
1. User Query â†’ Initial Retrieval
   ç”¨æˆ·æŸ¥è¯¢ â†’ åˆå§‹æ£€ç´¢

2. Relevance Grading â†’ Filter Documents
   ç›¸å…³æ€§è¯„åˆ† â†’ è¿‡æ»¤æ–‡æ¡£

3. Decision: Enough Relevant Docs?
   åˆ¤æ–­ï¼šç›¸å…³æ–‡æ¡£æ˜¯å¦è¶³å¤Ÿï¼Ÿ
   
   â”œâ”€ YES â†’ Generate Answer
   â”‚         ç”Ÿæˆç­”æ¡ˆ
   â”‚
   â””â”€ NO  â†’ Rewrite Query â†’ Re-retrieve â†’ Generate Answer
            é‡å†™æŸ¥è¯¢ â†’ é‡æ–°æ£€ç´¢ â†’ ç”Ÿæˆç­”æ¡ˆ
```

## ğŸ“Š Performance / æ€§èƒ½

- **Response Time**: < 3s (P95) / å“åº”æ—¶é—´
- **Retrieval Accuracy**: > 80% / æ£€ç´¢å‡†ç¡®ç‡
- **Answer Relevance**: > 85% / ç­”æ¡ˆç›¸å…³æ€§

## ğŸ¤ Contributing / è´¡çŒ®

Contributions are welcome! Please feel free to submit a Pull Request.

æ¬¢è¿è´¡çŒ®ï¼è¯·éšæ—¶æäº¤Pull Requestã€‚

## ğŸ“ License / è®¸å¯è¯

This project is open source and available under the MIT License.

æœ¬é¡¹ç›®æ˜¯å¼€æºçš„ï¼Œé‡‡ç”¨MITè®¸å¯è¯ã€‚

## ğŸ™ Acknowledgments / è‡´è°¢

- OpenAI for GPT-4 and embeddings API
- Qdrant for vector database
- Streamlit for the amazing UI framework
- LangChain for RAG utilities

## ğŸ“§ Contact / è”ç³»æ–¹å¼

For questions or support, please open an issue on GitHub.

å¦‚æœ‰é—®é¢˜æˆ–éœ€è¦æ”¯æŒï¼Œè¯·åœ¨GitHubä¸Šæå‡ºissueã€‚

---

**Note**: This is a demonstration project for job applications. Ensure you have appropriate API keys and comply with all terms of service.

**æ³¨æ„**ï¼šè¿™æ˜¯ä¸€ä¸ªç”¨äºæ±‚èŒç”³è¯·çš„æ¼”ç¤ºé¡¹ç›®ã€‚è¯·ç¡®ä¿ä½ æœ‰é€‚å½“çš„APIå¯†é’¥å¹¶éµå®ˆæ‰€æœ‰æœåŠ¡æ¡æ¬¾ã€‚
